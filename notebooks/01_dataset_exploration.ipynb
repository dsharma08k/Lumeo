{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lumeo - Dataset Exploration\n",
    "\n",
    "This notebook explores the LOL (LOw-Light) dataset for the low-light image enhancement project.\n",
    "\n",
    "**Dataset Structure:**\n",
    "- Training: 485 paired images (low â†’ high)\n",
    "- Validation: 15 paired images\n",
    "- Test: 335 unpaired low-light images (no ground truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (upload dataset to Drive first)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set dataset paths - UPDATE THESE TO YOUR DRIVE PATHS\n",
    "DATASET_ROOT = '/content/drive/MyDrive/Lumeo/datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "TRAIN_LOW = os.path.join(DATASET_ROOT, 'LOLdataset/our485/low')\n",
    "TRAIN_HIGH = os.path.join(DATASET_ROOT, 'LOLdataset/our485/high')\n",
    "VAL_LOW = os.path.join(DATASET_ROOT, 'LOLdataset/eval15/low')\n",
    "VAL_HIGH = os.path.join(DATASET_ROOT, 'LOLdataset/eval15/high')\n",
    "TEST_ROOT = os.path.join(DATASET_ROOT, 'Test/Test')\n",
    "\n",
    "print(f\"Train Low: {TRAIN_LOW}\")\n",
    "print(f\"Train High: {TRAIN_HIGH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(path):\n",
    "    \"\"\"Count PNG images in directory\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return 0\n",
    "    return len([f for f in os.listdir(path) if f.endswith('.png')])\n",
    "\n",
    "def get_image_names(path):\n",
    "    \"\"\"Get sorted list of image names\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return []\n",
    "    return sorted([f for f in os.listdir(path) if f.endswith('.png')])\n",
    "\n",
    "# Count images\n",
    "print(\"=== Dataset Statistics ===\")\n",
    "print(f\"Training Low:  {count_images(TRAIN_LOW)} images\")\n",
    "print(f\"Training High: {count_images(TRAIN_HIGH)} images\")\n",
    "print(f\"Validation Low:  {count_images(VAL_LOW)} images\")\n",
    "print(f\"Validation High: {count_images(VAL_HIGH)} images\")\n",
    "\n",
    "# Count test images\n",
    "test_dirs = ['DICM', 'Fusion', 'LIME', 'MEF', 'NPE', 'VV', 'low']\n",
    "print(\"\\n=== Test Dataset ===\")\n",
    "total_test = 0\n",
    "for d in test_dirs:\n",
    "    path = os.path.join(TEST_ROOT, d)\n",
    "    count = count_images(path)\n",
    "    if count > 0:\n",
    "        print(f\"  {d}: {count} images\")\n",
    "        total_test += count\n",
    "print(f\"  Total Test: {total_test} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify pairing: check that low and high have matching filenames\n",
    "train_low_names = set(get_image_names(TRAIN_LOW))\n",
    "train_high_names = set(get_image_names(TRAIN_HIGH))\n",
    "\n",
    "matched = train_low_names.intersection(train_high_names)\n",
    "unmatched_low = train_low_names - train_high_names\n",
    "unmatched_high = train_high_names - train_low_names\n",
    "\n",
    "print(f\"\\n=== Pairing Verification ===\")\n",
    "print(f\"Matched pairs: {len(matched)}\")\n",
    "print(f\"Unmatched in low: {len(unmatched_low)}\")\n",
    "print(f\"Unmatched in high: {len(unmatched_high)}\")\n",
    "\n",
    "if len(unmatched_low) > 0:\n",
    "    print(f\"  Missing high counterparts: {list(unmatched_low)[:5]}...\")\n",
    "if len(unmatched_high) > 0:\n",
    "    print(f\"  Missing low counterparts: {list(unmatched_high)[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Sample Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    \"\"\"Load image and convert to RGB\"\"\"\n",
    "    return np.array(Image.open(path).convert('RGB'))\n",
    "\n",
    "def display_pairs(low_dir, high_dir, num_pairs=5, seed=42):\n",
    "    \"\"\"Display low-light and corresponding high-light pairs\"\"\"\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Get common image names\n",
    "    low_names = set(get_image_names(low_dir))\n",
    "    high_names = set(get_image_names(high_dir))\n",
    "    common = sorted(list(low_names.intersection(high_names)))\n",
    "    \n",
    "    # Sample random pairs\n",
    "    samples = random.sample(common, min(num_pairs, len(common)))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_pairs, 2, figsize=(12, 4*num_pairs))\n",
    "    if num_pairs == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, name in enumerate(samples):\n",
    "        low_img = load_image(os.path.join(low_dir, name))\n",
    "        high_img = load_image(os.path.join(high_dir, name))\n",
    "        \n",
    "        axes[idx][0].imshow(low_img)\n",
    "        axes[idx][0].set_title(f'Low-Light: {name}')\n",
    "        axes[idx][0].axis('off')\n",
    "        \n",
    "        axes[idx][1].imshow(high_img)\n",
    "        axes[idx][1].set_title(f'Normal-Light: {name}')\n",
    "        axes[idx][1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"=== Training Samples ===\")\n",
    "display_pairs(TRAIN_LOW, TRAIN_HIGH, num_pairs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Validation Samples ===\")\n",
    "display_pairs(VAL_LOW, VAL_HIGH, num_pairs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Dimension Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dimensions(directory, sample_size=50):\n",
    "    \"\"\"Analyze image dimensions in directory\"\"\"\n",
    "    names = get_image_names(directory)\n",
    "    if len(names) > sample_size:\n",
    "        names = random.sample(names, sample_size)\n",
    "    \n",
    "    widths, heights = [], []\n",
    "    for name in names:\n",
    "        img = Image.open(os.path.join(directory, name))\n",
    "        widths.append(img.width)\n",
    "        heights.append(img.height)\n",
    "    \n",
    "    return {\n",
    "        'min_w': min(widths), 'max_w': max(widths), 'mean_w': np.mean(widths),\n",
    "        'min_h': min(heights), 'max_h': max(heights), 'mean_h': np.mean(heights),\n",
    "        'unique_sizes': len(set(zip(widths, heights)))\n",
    "    }\n",
    "\n",
    "print(\"=== Image Dimensions ===\")\n",
    "train_dims = analyze_dimensions(TRAIN_LOW)\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  Width:  min={train_dims['min_w']}, max={train_dims['max_w']}, mean={train_dims['mean_w']:.0f}\")\n",
    "print(f\"  Height: min={train_dims['min_h']}, max={train_dims['max_h']}, mean={train_dims['mean_h']:.0f}\")\n",
    "print(f\"  Unique sizes: {train_dims['unique_sizes']}\")\n",
    "\n",
    "val_dims = analyze_dimensions(VAL_LOW)\n",
    "print(f\"\\nValidation Set:\")\n",
    "print(f\"  Width:  min={val_dims['min_w']}, max={val_dims['max_w']}, mean={val_dims['mean_w']:.0f}\")\n",
    "print(f\"  Height: min={val_dims['min_h']}, max={val_dims['max_h']}, mean={val_dims['mean_h']:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Brightness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_brightness(directory, sample_size=30):\n",
    "    \"\"\"Compute mean brightness (luminance) of images\"\"\"\n",
    "    names = get_image_names(directory)\n",
    "    if len(names) > sample_size:\n",
    "        names = random.sample(names, sample_size)\n",
    "    \n",
    "    brightness_values = []\n",
    "    for name in names:\n",
    "        img = np.array(Image.open(os.path.join(directory, name)).convert('RGB')) / 255.0\n",
    "        # Luminance formula: 0.299*R + 0.587*G + 0.114*B\n",
    "        luminance = 0.299 * img[:,:,0] + 0.587 * img[:,:,1] + 0.114 * img[:,:,2]\n",
    "        brightness_values.append(luminance.mean())\n",
    "    \n",
    "    return brightness_values\n",
    "\n",
    "# Compute brightness for low and high\n",
    "low_brightness = compute_brightness(TRAIN_LOW)\n",
    "high_brightness = compute_brightness(TRAIN_HIGH)\n",
    "\n",
    "print(\"=== Brightness Analysis ===\")\n",
    "print(f\"Low-light images:  mean={np.mean(low_brightness):.3f}, std={np.std(low_brightness):.3f}\")\n",
    "print(f\"Normal-light images: mean={np.mean(high_brightness):.3f}, std={np.std(high_brightness):.3f}\")\n",
    "print(f\"\\nBrightness ratio (high/low): {np.mean(high_brightness)/np.mean(low_brightness):.2f}x\")\n",
    "\n",
    "# Plot histogram\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "ax.hist(low_brightness, bins=15, alpha=0.7, label='Low-Light', color='#333333')\n",
    "ax.hist(high_brightness, bins=15, alpha=0.7, label='Normal-Light', color='#FFD700')\n",
    "ax.set_xlabel('Mean Brightness')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Brightness Distribution: Low vs Normal Light')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify Shape Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_shape_matching(low_dir, high_dir, sample_size=50):\n",
    "    \"\"\"Verify that low and high pairs have matching shapes\"\"\"\n",
    "    low_names = set(get_image_names(low_dir))\n",
    "    high_names = set(get_image_names(high_dir))\n",
    "    common = sorted(list(low_names.intersection(high_names)))\n",
    "    \n",
    "    if len(common) > sample_size:\n",
    "        common = random.sample(common, sample_size)\n",
    "    \n",
    "    mismatched = []\n",
    "    for name in common:\n",
    "        low_img = Image.open(os.path.join(low_dir, name))\n",
    "        high_img = Image.open(os.path.join(high_dir, name))\n",
    "        \n",
    "        if low_img.size != high_img.size:\n",
    "            mismatched.append((name, low_img.size, high_img.size))\n",
    "    \n",
    "    return mismatched\n",
    "\n",
    "print(\"=== Shape Verification ===\")\n",
    "mismatched = verify_shape_matching(TRAIN_LOW, TRAIN_HIGH)\n",
    "if len(mismatched) == 0:\n",
    "    print(\"All sampled pairs have matching shapes!\")\n",
    "else:\n",
    "    print(f\"Found {len(mismatched)} mismatched pairs:\")\n",
    "    for name, low_size, high_size in mismatched[:5]:\n",
    "        print(f\"  {name}: low={low_size}, high={high_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary\n",
    "\n",
    "**Key Findings:**\n",
    "- Dataset is properly paired (same filenames in low/high directories)\n",
    "- Images have varying dimensions - will need resizing for training\n",
    "- Low-light images have ~3-5x lower brightness than normal\n",
    "- All pairs have matching shapes\n",
    "\n",
    "**Next Steps:**\n",
    "1. Create PyTorch Dataset with proper transforms\n",
    "2. Implement U-Net model architecture\n",
    "3. Train with combined loss (L1 + Perceptual + SSIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset exploration complete!\")\n",
    "print(\"\\nReady for model training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
